[{"categories":["Architecture"],"content":"중앙 로그시스템 설계","date":"2022-07-14","objectID":"/kubernetess_log_system_architecture_strategy/","tags":["AWS","ELK","FluentD","Filebeat","Kafka","Kinesis","Elastic Search"],"title":"AWS + 쿠버네티스 환경에서의 로그 시스템 구축 전략","uri":"/kubernetess_log_system_architecture_strategy/"},{"categories":["Architecture"],"content":"AWS 클라우드 환경 여러 서비스 서버들에 대한 로그중앙화 관리 아키텍처 설계 ","date":"2022-07-14","objectID":"/kubernetess_log_system_architecture_strategy/:0:0","tags":["AWS","ELK","FluentD","Filebeat","Kafka","Kinesis","Elastic Search"],"title":"AWS + 쿠버네티스 환경에서의 로그 시스템 구축 전략","uri":"/kubernetess_log_system_architecture_strategy/"},{"categories":["Architecture"],"content":"1 Description AWS 클라우드 환경 내에 클라우드를 배포/운영하는 시스템들에 대해 로그 시스템을 중앙화하는 방법에 대한 아키텍처 설계를 진행한다.(구체적인 세부 설정 - 리소스 구성 스펙 및 운영상 편의를 위한 옵션 설정에 대한 설명은 제외) ","date":"2022-07-14","objectID":"/kubernetess_log_system_architecture_strategy/:1:0","tags":["AWS","ELK","FluentD","Filebeat","Kafka","Kinesis","Elastic Search"],"title":"AWS + 쿠버네티스 환경에서의 로그 시스템 구축 전략","uri":"/kubernetess_log_system_architecture_strategy/"},{"categories":["Architecture"],"content":"2 Background 로그 분석 시스템에 있어 Elastic Search는 가장 대표적인 로그 분석 시스템이다. Elastic Search란? 가장 대표적인 구성으로 ELK를 많이 언급한다. ELK는 로그 시스템을 구축하기 위한 모듈의 조합으로 Data Shipper(아래 이미지에서는 beats가 대행) 역할 및 Data Parsing을 담당하는 Logstash, 데이터에 대한 저장/색인/조회 역할을 하는 Elastic Search, 사용자에게 UI를 제공하는 Kibana 조합이다. ","date":"2022-07-14","objectID":"/kubernetess_log_system_architecture_strategy/:2:0","tags":["AWS","ELK","FluentD","Filebeat","Kafka","Kinesis","Elastic Search"],"title":"AWS + 쿠버네티스 환경에서의 로그 시스템 구축 전략","uri":"/kubernetess_log_system_architecture_strategy/"},{"categories":["Architecture"],"content":"3 Architecture ELK 조합을 사용한다면 아래 그림과 같은 구조로 간단히 구성할 수 있다. ","date":"2022-07-14","objectID":"/kubernetess_log_system_architecture_strategy/:3:0","tags":["AWS","ELK","FluentD","Filebeat","Kafka","Kinesis","Elastic Search"],"title":"AWS + 쿠버네티스 환경에서의 로그 시스템 구축 전략","uri":"/kubernetess_log_system_architecture_strategy/"},{"categories":["Architecture"],"content":"3.1 Basic ELK를 기반으로 하는 기본 구성도 서버 인스턴스에서 파일에 로그를 생성하고, Data Shipper인 파일비트를 통해 로그를 전송한다. json으로 구성되어 있다면, ES(Elastic Search의 데이터 노드 적재)로 직접 전달할 수도 있고, 데이터 파싱을 위해서 logstash를 거쳐 ES에 저장 가능하다. Q) 로그 적재 시에 json을 써서 logstash를 안써도 되지 않나요? 로그 시스템이 단일 서버에서만 사용한다면 가능할 수 있지만, 다양한 서버에서 로그 수집에 대한 요구사항(인덱스 구성 및 데이터 포맷)이 다를 수 있기에 일반적으로 데이터 파싱 모듈을 조합한 구성으로 설계한다. Q) 네트워크 구간에 장애에 따른 데이터 유실이 있을수 있나요? filebeat에 경우 전송 성공한 기록 index 값을 관리하고 있기에 전송하는 Client단에는 보장 가능합니다. 쿠버네티스의 환경에서 서비스 인스턴스에 문제로 pod이 재시동이 된어도 로그 수집 경로를 Worker Node로 하여 보관 가능합니다. Logstash는 20개의 Fixed-Size Event 제한이 있어(메모리 대기 큐) 재시작시 지속성을 위해 외부 스트림 큐를 추가적으로 구성한다. 위 내용에 대한 것을 반영한다면 다음과 같은 아키텍처 설계를 구성할 수 있다. ELK + KAFKA 구성 ","date":"2022-07-14","objectID":"/kubernetess_log_system_architecture_strategy/:3:1","tags":["AWS","ELK","FluentD","Filebeat","Kafka","Kinesis","Elastic Search"],"title":"AWS + 쿠버네티스 환경에서의 로그 시스템 구축 전략","uri":"/kubernetess_log_system_architecture_strategy/"},{"categories":["Architecture"],"content":"3.2 Extension 그림에서 그럼 대체 가능한 구성들은 무엇이 있고, 추가적으록 고민해야할 부분들은 언급하며 확장해보자. (개인적인 생각) 로그 수집 시스템에 구성 모듈에 대해 분류를 나눈다면 데이터 전송을 하는 Data Shipper, 누적되는 데이터를 보관 및 유실방지를 위한 Data Stream Queue, ES의 데이터 노드 전 데이터 파싱을 위한 Data Indexer, 데이터 활용을 위한 Data Visualization으로 구분 지을 수 있다. 분류 조건으로 필요한 도구들은 대표적으로 아래와 같다. 분류 도구 Data Shipper Beats:Filebeat, FluentBit, … Data Stream Queue Kafka, Kinesis, RedPanda, … Data Indexer Logstash, fluentd, … Data Visualization Kibana, Grafana, … 3.2.1 Data Shipper 비교 Filebeat vs FluentBit 장점 단점 FileBeat ES에서 제공하기에 EOS에 대한 이슈 및 문제 발생시 Communication Point가 정확함 모니터링이 다른 도구에 비해 빈약하며, 파일 전송 외에 필터 및 파싱에 대한 라이브러리 제약이 많음 FluentBit FluentD에 경량화로 모니터링 기능이 있으며 타 모듈보다 커뮤니티에서 더 활발히 사용하여 Issue 히스토리가 상대적으로 많음 Enterprise Resource Planning이 없음 (나라면) 다음 이유로 FileBeat를 사용 할 것 같다. 상용 서비스 반영이니 Enterprise 레벨로 서비스 받을 수 있다는 장점 해외 기업이니 느리다. 정말 Deep한 이슈들이 아니면 딱히 문의 할 일이 없을 듯 커뮤니티 언급은 FluentBit가 많지만 사용 현황으로 보면 FileBeat가 훨씬 많으므로 소프트웨어 대한 신뢰성은 이미 검증 된것으로 간주 기능성 데이터 전송을 제외하고는 다른 기능을 쓸 필요 없다고 생각하며 서비스 되는 팟에서는 가장 단순하고 심플하게 사용이 맞다고 생각함 3.2.2 Data Stream Queue 비교 https://www.softkraft.co/aws-kinesis-vs-kafka-comparison/ https://food4ithought.com/2019/11/20/apache-kafka-vs-aws-kinesis/ 장점 단점 Kafka Kinesis보다 성능이 좋으며, 구성이 유연하며, Replication의 복잡한 설정으로 성능 제어를 세밀하게 조정 가능 관리를 위한 전문 인력 리소스가 필요 Kinesis 설정이 단순하며 구성도 단순하여 서비스 구성 및 운영시 learning curve가 적음 카프카 대비 사용룰은 1/10이며, 기능 제한이 많음 RedPanda 성능은 카프카에 몇배 이상 좋다고힘 usecase가 많이 보이지 않아 이슈 대응이 불가능 할 수 있음 AWS에서 managed로 제공되는 AWS MSK가 있지만, kafka의 새로운 버전 릴리즈시 호환성 및 기능 제공에 대한 간극이 있을 수 있음. 그리고 많이 사용되지 않는다는 치명적인 단점을 지님. 키네시스와 카프카 선정하기 위하기 질문 3가지 모두 No라면 키네시스를 사용하는 것을 권고한다. 카프카에 대한 전문 지식을 가진 인원이 있나요? 1000 TPS보다 많은 처리가 필요한가요? 메세지가 7일 이상 지속되어야 하는가? (나라면) 다음 이유로 Kafka를 사용 할 거 같다. 비용으로 보면 다변화되는 환경에서의 요구사항을 증가하고 또한 개발 서버 및 로그도 증가할 것이다. 키네시스의 경우에는 사용 시간 및 메시지 처리량에 따른 과금과 로그량이 많아질 것이기 때문에 비용이 지속적으로 증가 할 거라 생각 됨 사용 비율도 카프카가 압도적으로 높기 때문에 유지 보수를 위한 운영 처리에도 더 효율적이라 판단됨 3.2.3 Data Indexer 비교 https://logz.io/blog/fluentd-logstash/ https://www.upsolver.com/blog/comparing-apache-kafka-amazon-kinesis Event Routing Plugin Ecosystem Transport Performance Logstash Algorithmic statements Centralized Deploy With Redis for Reliability Use more memory. Use Elastic Beats for leaft. Fluentd Tags Decentralized Built-in reliability but hard to configure. Uses less memory. Use Fluent Bit and Fluentd forwarder for leafts. 장점 단점 Logstash ES에서 제공하는 것으로 업데이트에 따라 동일 버전사용하므로 고민이 필요 없음 kafka나 kinesis 시스템 필요, 운영 리소스가 많아짐 FluentD 독립적인 시스템으로 생각 가능하며, Data Queue 모듈이 필요 없음 logstash보다는 es와 궁합이 낮음 (나라면) 다음 이유로 FluentD를 사용 할 거 같다. ES 버전 업데이트가 빈번하지만 설치 후 ES를 업데이트가 필요할 때는 보안 취약점 관련해서 업데이트가 하겠지만, 실상 내부 운영으로 사용되기 때문에 이마저도 업데이트 하지 않는다. kafka나 kinesis도 필요 없이 운영 가능하다. (운영하는 시스템은 적을 수록 좋기 때문에) 실제 FluentD만으로도 충분히 상용 운영이 가능한 것을 확인하였으며, 기능상으로만 봐도 입력받고 파싱하고 출력을 내보내는 것으로 ES와 합을 맞추기 위한 기능으로 충분히 활용 가능하다. FluentD도 복구전략으로 파일에 쓰고 관리를 하기 때문에 예외적인 Edge Case들이 아닌 이상은 복구전략으로 문제 없다. 3.2.4 Data Visualization 비교 (나라면) Kibana는 필수/Grafana는 선택/다른 기타 등등 선택 Grafana는 고정된 쿼리를 날려서 화면의 View를 보여주기 때문에, 인터페이스가 더 깔끔하고 보기 좋을 수는 있지만, Kibana에서처럼 키에 대한 필터를 필요할 때마다 동적으로 설정하기는 어렵기 때문에 Kibana는 필수 Grafana는 선택이라고 생각한다. ","date":"2022-07-14","objectID":"/kubernetess_log_system_architecture_strategy/:3:2","tags":["AWS","ELK","FluentD","Filebeat","Kafka","Kinesis","Elastic Search"],"title":"AWS + 쿠버네티스 환경에서의 로그 시스템 구축 전략","uri":"/kubernetess_log_system_architecture_strategy/"},{"categories":["Architecture"],"content":"3.3 Final Architecture 3.3.1 내가 생각한 아키텍처 위에서 조사했던 내용 기반으론 내가 생각했던 아키텍처의 그림은 아래와 같다. 내가 생각한 모듈 기반 로그시스템 구성 3.3.2 피드백 from 똑똑한 놈들 and Google 네이버/카카오 기타 등등에 다른 회사 지인들에게는 어떻게 쓰는지가 궁금해서 내가 생각했던거를 공유하고 피드백을 받아보았다. 돌아온 답변 “생각대로 해도 되는데, 정말 큰 기업이 아니고서는 Managed Service를 쓰는게 훨씬 비용측면에서 유리할거다.” FluentD도 그렇지만 결론적으로 서버 운영 비용이 들 뿐더라, AWS 기능들을 조합하는게 좋고 alive 여부/리소스 모니터링등 신뢰성을 가지려면 전문인력이 필요한데 그런 구성이 아니라면 하지말라는게 평론이였다. 그러면 AWS에 로그시스템은 어떤 기능등을 조합해서 쓰고 있는가? 베이스 : Kinesis/Amazon MSK-카프카 (대부분 Kinesis 사용), Amazon ES 그 외 : Lambda/S3 AWS에서 조합 로그시스템 구성 로그 데이터 전송에 경우는 어플리케이션과 분리하여 의존성을 줄이는 방법으로 파일로 로그를 쓰고, filebeat/Amazon CloudWatch/FluentBit를 사용한다. (나라면) 로그 공통 룰을 가지고 개발이 되었다면, filebeat/fluentBit를 둘중 하나 사용할 것이고, 예외적인 모듈이 한개라도 있다면 마음편히 cloudwatch를 사용할 것이다. 위의 s3를 선택한 그려놓은 이유는 필요에 따라 ES가 아닌 다른 모듈에서 로그 정보를 활용할 수 있기 때문에 확장 개념으로 보면 된다. ","date":"2022-07-14","objectID":"/kubernetess_log_system_architecture_strategy/:3:3","tags":["AWS","ELK","FluentD","Filebeat","Kafka","Kinesis","Elastic Search"],"title":"AWS + 쿠버네티스 환경에서의 로그 시스템 구축 전략","uri":"/kubernetess_log_system_architecture_strategy/"},{"categories":["Architecture"],"content":"4 Review 고민은 엄청 많이 한거에 비해 내가 생각했던 거와 달리 결론적으로는 하나도 반영되지 않았다. 우선 많은 기업에서 클라우드의 Managed Service를 많이 사용하고 있음에도 불구하고 나의 경험부족으로 인해 신뢰성을 갖지 못했고 그로 인해 결과 도출하는데 있어 빙빙 돌아온 경향이 있었다. 또한 비용만 생각하다보니 on-premise 기반의 아키텍처로 생각이 bias되었던 부분들에 대해 부족한 점을 느낀다. 나의 지식의 부족함을 반성하고 열심히 경험쌓고 배워야겠다. ","date":"2022-07-14","objectID":"/kubernetess_log_system_architecture_strategy/:4:0","tags":["AWS","ELK","FluentD","Filebeat","Kafka","Kinesis","Elastic Search"],"title":"AWS + 쿠버네티스 환경에서의 로그 시스템 구축 전략","uri":"/kubernetess_log_system_architecture_strategy/"},{"categories":["Architecture"],"content":"5 Reference https://findmypiece.tistory.com/96 ","date":"2022-07-14","objectID":"/kubernetess_log_system_architecture_strategy/:5:0","tags":["AWS","ELK","FluentD","Filebeat","Kafka","Kinesis","Elastic Search"],"title":"AWS + 쿠버네티스 환경에서의 로그 시스템 구축 전략","uri":"/kubernetess_log_system_architecture_strategy/"},{"categories":["Node"],"content":"토이프로젝트를 진행하며 Node와 React를 학습한다.","date":"2021-06-30","objectID":"/chapter1_start/","tags":["Node","React"],"title":"[Node+React] Chapter1 시작하기","uri":"/chapter1_start/"},{"categories":["Node"],"content":"Node+React 1강 ","date":"2021-06-30","objectID":"/chapter1_start/:0:0","tags":["Node","React"],"title":"[Node+React] Chapter1 시작하기","uri":"/chapter1_start/"},{"categories":["Node"],"content":"1 공부를 시작하며… 서버 개발자가 된 이후부터는 Spring 이외 다른 언어 및 프레임워크를 다뤄 볼 기회가 없었다. 회사 프로젝트도 리팩토링도 해보고 개발 관련 책들도 접하지만 토이 프로젝트를 진행하지 않다보니, 학습 후에도 머리에 남아 있지 않았다. 개발에 있어 최근 Node와 React를 많이 사용기에 위 2개를 사용하여 학습하며 토이 프로젝트를 진행해보려고 합니다. 목표는 Admin 사이트(로그인, 통계 대시보드등) 개발하기~! ","date":"2021-06-30","objectID":"/chapter1_start/:1:0","tags":["Node","React"],"title":"[Node+React] Chapter1 시작하기","uri":"/chapter1_start/"},{"categories":["Node"],"content":"2 환경 설정 ","date":"2021-06-30","objectID":"/chapter1_start/:2:0","tags":["Node","React"],"title":"[Node+React] Chapter1 시작하기","uri":"/chapter1_start/"},{"categories":["Node"],"content":"2.1 개발 환경 OS : MAC Development Tool : Visual Studio Code Framework : NodeJs v16.4.0 PackageManager : yarn v1.22.10 npm도 가능 자신이 익숙한걸로~! - NPM? Yarn? , 본인에게 편한게 최고! 설치 방법 ~$ brew install yarn or ~$ npm install -g yarn ","date":"2021-06-30","objectID":"/chapter1_start/:2:1","tags":["Node","React"],"title":"[Node+React] Chapter1 시작하기","uri":"/chapter1_start/"},{"categories":["Node"],"content":"2.2 VSCode(Visual Studio Code) 설정 VSCode/Yarn/NodeJs 전부 설치를 했다면 VSCode에서 사용하기 좋은 확장 플러그인 및 아래 기능을 설정하도록 하자. Prettier : Code Formater로 협업 시 코드 규격을 자동 적용해 준다. VSCode Formater 인 Prettier 완벽 적용하기 VSCode 쉘에서 code 명령어로 visual studio code 열기 ","date":"2021-06-30","objectID":"/chapter1_start/:2:2","tags":["Node","React"],"title":"[Node+React] Chapter1 시작하기","uri":"/chapter1_start/"},{"categories":["Node"],"content":"3 시작하기 ~$ mkdir test ~$ cd test test$ yarn init test$ code . 프로젝트 폴더를 생성하고, yarn init을 통해 프로젝트 초기화를 통해 pakcage.json을 생성하고 VSCode를 실행한다. 그리고 TypeScript를 사용할 예정이다. TypeScript는 자바스크립트를 사용함에 있어, 높은 가독성과 코드 품질을 제공하기 위한 것으로 컴파일 환경에서 에러를 잡아 낼 수도 있다. 한눈에 보는 타입스크립트 node에서 많은 기능을 제공하는 라이브러리인 lodash와 TypeScript를 transpiling(compile이라고도 명명 하지만 typescript에서 javascript로 변환하는 것)과 실행을 함께 하기 위해 사용되는 ts-node를 설치한다. 그 이후 테스트 코드를 생성해보자. test$ yarn tsc --init //컴파일러 옵션을 정의된 tsconfig.js 생성 test$ yarn add lodash test$ yarn add ts-node --dev /*(src/test.ts)*/ import _ from \"lodash\"; var foo = [4, 2, 8, 6]; console.log(_.min(foo)); /*(src/test.js)*/ var _ = require(\"lodash\"); var foo = [4, 2, 8, 6]; console.log(_.min(foo)); test$ ts-node src/test.js 2 test$ node src/test.js 2 /* 동일 결과가 나왔다면 끝 */ ","date":"2021-06-30","objectID":"/chapter1_start/:3:0","tags":["Node","React"],"title":"[Node+React] Chapter1 시작하기","uri":"/chapter1_start/"},{"categories":["Node"],"content":"4 회고 우선 첫 날이라 Warm-up 수준으로 진행하였다, 육아로 인해 밤 11시부터 시작하였는데 강의 진행해주신 JHW님 감사합니다. ","date":"2021-06-30","objectID":"/chapter1_start/:4:0","tags":["Node","React"],"title":"[Node+React] Chapter1 시작하기","uri":"/chapter1_start/"},{"categories":["AWS"],"content":"[AWS] CloudFront의 Signed URL 사용법 using JAVA ","date":"2021-02-23","objectID":"/aws_cloudfront_and_s3/:0:0","tags":["Cloud","CDN"],"title":"[AWS] Signed URL를 사용한 CloudFront","uri":"/aws_cloudfront_and_s3/"},{"categories":["Web"],"content":"Timeout 뜻은 알겠으나, 그 종류가 너무 많다. 한번에 정리하자.","date":"2020-09-04","objectID":"/timeout/","tags":["Web","Socket","timeout"],"title":"Timeout에 대한 정리","uri":"/timeout/"},{"categories":["Web"],"content":"HTTP 통신에 TIMEOUT 설정 한방에 한번에 이해하자. 처음 포스팅 때 DB Connection Pool 사용을 위해 DBCP 라이브러리 뒤적뒤적 하면서 성능비교를 했었다. 근데 이번에는 Http Connection Library 로 okhttp 사용하였는데 timeout 설정을 각 서버별로 다르게 적용해야 했는데 매번 헷갈린거 같아, 설명 및 그림으로 나타내어 리마인드한다. Timeout 설명 Connection 요청부터 TCP Handshake가 완료되기까지의 지속시간을 나타낸다. (default 10s, unlimit 0s) Read 서버에 요청 이후 응답의 패킷 사이에 전송시간으로 두 데이터 패킷 사이의 최대 비활성 시간을 정의한다. (default 10s, unlimit 0s) Write 서버로 전송하기 위한 패킷 사이에 전송시간으로 두 데이터 패킷 사이의 최대 비활성 시간을 정의한다. (default 10s, unlimit 0s) Call 호출 시작부터 완료까지의 시간제한으로 DNS 확인, 연결, 요청 본문 작성, 서버처리 및 응답 본문 읽기를 포함한다. (default 0s, unlimit 0s) ","date":"2020-09-04","objectID":"/timeout/:0:0","tags":["Web","Socket","timeout"],"title":"Timeout에 대한 정리","uri":"/timeout/"},{"categories":["Python"],"content":"아나콘다를 사용한 가상환경 구축 방법을 익힌다.","date":"2020-08-22","objectID":"/anaconda_usage/","tags":["Virtual Environment","Python"],"title":"ANACONDA 사용법","uri":"/anaconda_usage/"},{"categories":["Python"],"content":"Anaconda를 사용하여 독립적인 가상환경을 구성하기 새로운 툴을 사용할 때에는 설명과 이름에 대한 유래를 항상 살펴본다. 아나콘다는 패키지 관리와 디플로이를 단순하게 할 목적으로 데이터 사이언스를 위해 파이썬과 R 프로그래밍 언어를 지원한다. 아나콘다라는 이름의 유래를 보면 파이썬이 뱀이다보니 패키지나 관련 프로젝트들도 뱀의 이름으로부터 생성되었다고 한다. 아마 모든 개발자들 겪는 어려움 중 하나가 환경셋팅일 것이다. 그래서 Docker 같은 툴의 필요성 및 그에 따른 활용이 대두되는 거 같다. Conda를 사용함으로써, 버전 호환성, 라이브러리 충돌 및 관리의 문제들을 해결해준다. (virtualEnv도 많이 사용) ","date":"2020-08-22","objectID":"/anaconda_usage/:0:0","tags":["Virtual Environment","Python"],"title":"ANACONDA 사용법","uri":"/anaconda_usage/"},{"categories":["Python"],"content":"1 설치하기 각 OS별로 아래 사이트에서 다운로드 해서 Next는 누르면 완료 https://www.anaconda.com/products/individual MiniConda MAC 한번에 설치하기 wget https://repo.anaconda.com/miniconda/Miniconda3-latest-MacOSX-x86_64.sh chmod -R 755 Miniconda3-latest-Linux-x86_64.sh ./Miniconda3-latest-Linux-x86_64.sh ","date":"2020-08-22","objectID":"/anaconda_usage/:1:0","tags":["Virtual Environment","Python"],"title":"ANACONDA 사용법","uri":"/anaconda_usage/"},{"categories":["Python"],"content":"2 사용법 ","date":"2020-08-22","objectID":"/anaconda_usage/:2:0","tags":["Virtual Environment","Python"],"title":"ANACONDA 사용법","uri":"/anaconda_usage/"},{"categories":["Python"],"content":"2.1 기본 명령어 기능 명령어 패키지 삭제 conda clean 설정 조회/수정 conda config 새로운 가상환경 생성 conda create -n {env_name} python=3.6 설치된 아나콘다 정보 조회 conda info 패키지 설치 conda install -n {env_name} {package_name} 설치된 패키지 정보 conda list 설치된 패키지 삭제 conda remove -n {env_name} {package_name} 설치된 패키지 조회 conda search -n {env_name} {package_name} 환경 삭제 conda uninstall 설치된 패키지 업데이트 conda update -n {env_name} ","date":"2020-08-22","objectID":"/anaconda_usage/:3:0","tags":["Virtual Environment","Python"],"title":"ANACONDA 사용법","uri":"/anaconda_usage/"},{"categories":["Python"],"content":"2.2 기타 필요 명령어 기능 명령어 가상 환경 적용 source activate {env_name} 가상 환경 종료 source deactivate 가상 환경 복제 conda create -n {src_env_name} –clone {new_env_name} Export conda env export \u003e {filename}.yaml Import conda env create -f {filename}.yaml ","date":"2020-08-22","objectID":"/anaconda_usage/:4:0","tags":["Virtual Environment","Python"],"title":"ANACONDA 사용법","uri":"/anaconda_usage/"},{"categories":["Python"],"content":"3. 회고 직접 써 보니깐 확실히 편리하다. 로컬 셋팅되었던 환경의 정보를 전달해줄 수 있기 때문에, 프로젝트 공유하여 셋업시에 문제를 최소화 할 수 있다. 파이썬을 쓴다면 필수적으로 사용해야 한다. ","date":"2020-08-22","objectID":"/anaconda_usage/:5:0","tags":["Virtual Environment","Python"],"title":"ANACONDA 사용법","uri":"/anaconda_usage/"},{"categories":["Spring"],"content":"의존성 주입하는 방식과 추천 방법","date":"2020-08-20","objectID":"/spring_depedency_injection/","tags":["Spring","Dependency Injection"],"title":"스프링에 생성자로 의존성 주입 방법","uri":"/spring_depedency_injection/"},{"categories":["Spring"],"content":"의존성 주입 방법 종류 및 특징 ","date":"2020-08-20","objectID":"/spring_depedency_injection/:0:0","tags":["Spring","Dependency Injection"],"title":"스프링에 생성자로 의존성 주입 방법","uri":"/spring_depedency_injection/"},{"categories":["Spring"],"content":"1 서론 스프링 프레임워크를 사용하면서 컨트롤러에서 서비스 빈을 사용할 때에는 아래와 같이 필드 주입을 위해 @autowired 어노테이션을 사용하였다. @Controller public class TestController { @Autowired private TestService testService; .... } legacy 코드들을 통해 학습하면서, 필드 주입으로 간단하고 명확하게 사용하는 가장 좋은 방법이라고 생각하였다. 그러나 스프링 관련 동영상을 보다가 생성자 주입(Constructor Injection)을 사용하는 습관이 좋다라는 이야기를 듣고 주입에 대한 개념과 사용방법을 다시 한번 살펴보았다. ","date":"2020-08-20","objectID":"/spring_depedency_injection/:1:0","tags":["Spring","Dependency Injection"],"title":"스프링에 생성자로 의존성 주입 방법","uri":"/spring_depedency_injection/"},{"categories":["Spring"],"content":"2 주입 종류 및 예 ","date":"2020-08-20","objectID":"/spring_depedency_injection/:2:0","tags":["Spring","Dependency Injection"],"title":"스프링에 생성자로 의존성 주입 방법","uri":"/spring_depedency_injection/"},{"categories":["Spring"],"content":"2.1 생성자 주입(Constructor Injection) 스프링 가이드에 권장 방식으로 생성자에 @Autowired를 통해 주입을 할 수 있다. 단일 생성자에는 생략이 가능하며 2개이상의 생성자를 가지는 경우 @autowired 어노테이션을 전부 붙여주어야 한다. 생성자 객체를 생성할 때 빈을 주입되기 때문에 생성전 필요한 빈들을 찾게 된다. 다른 주입 방식들과의 차이점이며, 이 특징은 순환 참조(Circular Depencies)등의 방지가 가능하다. @Component public class TestComponent { private final TestService testService; // 단일 생성자인경우 @Autowired 생략이 가능 public TestComponent(TestService testService){ this.testService = testService; } } ","date":"2020-08-20","objectID":"/spring_depedency_injection/:2:1","tags":["Spring","Dependency Injection"],"title":"스프링에 생성자로 의존성 주입 방법","uri":"/spring_depedency_injection/"},{"categories":["Spring"],"content":"2.2 필드 주입(Field Injection) 필드 주입은 가독성 및 사용하기 편리하다. 필드 주입의 경우 빈을 생성한 후에 어노테이션이 붙은 필드에 해당하는 빈을 주입하는 방식이다. @Component public class TestComponent { @Autowired private TestService testService; ... } ","date":"2020-08-20","objectID":"/spring_depedency_injection/:2:2","tags":["Spring","Dependency Injection"],"title":"스프링에 생성자로 의존성 주입 방법","uri":"/spring_depedency_injection/"},{"categories":["Spring"],"content":"2.3 수정자 주입(Setter Injection) 수정자(Setter)를 사용한 방법으로 클래스의 캡슐화시 변수들을 getter/setter로 사용하는 방식과 동일하다. TestComponent 빈이 생성이 된 후 setTestService 메소드 호출을 통해 주입 되는 방식이며, 생성자 주입과 빈이 생성되는 순서가 다르기 때문에 final 사용은 불가능하다. @Component public class TestComponent { private TestService testService; @Autowired private void setTestService(TestService testService){ this.testService = testService; } } ","date":"2020-08-20","objectID":"/spring_depedency_injection/:2:3","tags":["Spring","Dependency Injection"],"title":"스프링에 생성자로 의존성 주입 방법","uri":"/spring_depedency_injection/"},{"categories":["Spring"],"content":"3 생성자 주입 방법을 써야하는 이유 ","date":"2020-08-20","objectID":"/spring_depedency_injection/:3:0","tags":["Spring","Dependency Injection"],"title":"스프링에 생성자로 의존성 주입 방법","uri":"/spring_depedency_injection/"},{"categories":["Spring"],"content":"3.1 순환 참조를 방지 @Service public class TestAService { @Autowired private TestBService testBService; private void callTestB(){ testBService.callTestA(); } } @Service public class TestBService { @Autowired private TestAService testAService; private void callTestA(){ testAService.callTestB(); } } 위 2개의 클래스 TestAService, TestBService 필드 주입을 통해 상호 서비스간의 참조하고 메소드들도 서로 참조하여 메소드 실행시에 stackOverflow가 발생하는 예제의 코드이다. (상호 참조하지 않는다면 문제가 발생할만한 비즈니스 로직상에 순환참조도 없을것이다.) 위 2개의 클래스를 가지는 어플리케이션을 구동하게 되면 각 서비스들의 빈이 생성이 된 후, 각자 의존성이 있는 빈이 컨테이너에 존재하기 때문에 실행에는 아무런 오류가 발생하지 않는다. @Service public class TestAService { private final TestBService testBService; public TestAService(TestBService testBService){ this.testBService = testBservice; } private void callTestB(){ testBService.callTestA(); } } @Service public class TestBService { private final TestAService testAService; public TestBService(TestAService testAService){ this.testAService = testAservice; } private void callTestA(){ testAService.callTestB(); } } 이번에는 생성자 주입을 통해 코드를 구성하였다. 자신의 빈을 생성하기 전에 의존성 있는 빈들을 검색하기 때문에 2개의 서비스 모두 생성되지 않고, 계속 서로의 생성자를 호출하게 되며, 스프링에서는 이것을 순환참조로 감지하여 오류 메세지를 전달한다. 어플리케이션을 동작시키면 다음과 같은 로그를 확인 할 수 있다. Log Description : The dependencies of some of the beans in the application context from a cycle ","date":"2020-08-20","objectID":"/spring_depedency_injection/:3:1","tags":["Spring","Dependency Injection"],"title":"스프링에 생성자로 의존성 주입 방법","uri":"/spring_depedency_injection/"},{"categories":["Spring"],"content":"4 회고 요약하자면 생성자 주입을 사용하면 컴파일 타임에 NPE 방지하면서 객체를 생성하고, 순환참조 방지도 가능하며, immutabliliy하게 final을 사용할 수 있다. 생성자 주입을 사용하도록 하자~! ","date":"2020-08-20","objectID":"/spring_depedency_injection/:4:0","tags":["Spring","Dependency Injection"],"title":"스프링에 생성자로 의존성 주입 방법","uri":"/spring_depedency_injection/"},{"categories":["Spring"],"content":"5 참조 스프링 - 생성자 주입을 사용해야 하는 이유, 필드인젝션이 좋지 않은 이유 순환 참조 해결하기 ","date":"2020-08-20","objectID":"/spring_depedency_injection/:5:0","tags":["Spring","Dependency Injection"],"title":"스프링에 생성자로 의존성 주입 방법","uri":"/spring_depedency_injection/"},{"categories":["Java"],"content":"Hikari cp의 원리를 설명한다.","date":"2020-06-30","objectID":"/hikaricp/","tags":["ConnectionPool","Java"],"title":"Hikari Connection Pool 파헤치기","uri":"/hikaricp/"},{"categories":["Java"],"content":"Hikari Connection Pool 동작 원리 및 옵션 설정 이해하기 CP(Connection Pool) 라이브러리 성능 검증 을 통해 Hikari 성능이 좋다는 것은 확인하였고, 실제 동작상 성능 향상을 위해 어떠한 이점을 가지는지를 확인하고자 동작 방식과 hikari에서 사용되는 옵션들에 대해서 이해해 보자. ","date":"2020-06-30","objectID":"/hikaricp/:0:0","tags":["ConnectionPool","Java"],"title":"Hikari Connection Pool 파헤치기","uri":"/hikaricp/"},{"categories":["Java"],"content":"1 Description 기존 사용되던 tomcat-dbcp, dbcp, bonecp 보다 더 빠르고, 가벼운 Connection Pool로 ‘zero-overhead’라고 할 정도의 경량화 된 라이브러리이다. hikari cp가 빠른 이유 코드 디자인 및 최적화를 통해 스레드 간의 잠금 경쟁이 크게 감소 JDK 및 cglib의 동적 프록시와 비교하여 javaassist(java 바이트 코드를 조작하는 수단을 제공하는 라이브러리)를 통해 클래스 파일을 직접 수정하여 생성된 프록시 클래스는 작동 속도가 빠름 FastList 및 사용자 정의 컬렉션 클래스 도입하여 세부 로직을 최적화하여 제공 ","date":"2020-06-30","objectID":"/hikaricp/:1:0","tags":["ConnectionPool","Java"],"title":"Hikari Connection Pool 파헤치기","uri":"/hikaricp/"},{"categories":["Java"],"content":"2 Architecture 다른 DBCP들과 아키텍쳐들은 유사하며, 아키텍쳐의 차이에 의한 성능차이가 아닌 pool(ConcurrentBag) 구조 및 관리 방법에 의한 것임을 확인 할 수 있습니다. GROUP Modules Description JMX HikariCOnfigMXBean, HikariPoolMXBean 데이터 수집을 통한 모니터링 제공 설정정보 HikariConfig 옵션 Connection Pool PoolBase, IBagStateListner, HikiarPool, ConcurrentBag Connection 관리 DataSource DataSource, HikariDataSource, Closeable Connection Pool을 지원하기 위한 인터페이스 Hikari Pool 구성도 ","date":"2020-06-30","objectID":"/hikaricp/:2:0","tags":["ConnectionPool","Java"],"title":"Hikari Connection Pool 파헤치기","uri":"/hikaricp/"},{"categories":["Java"],"content":"3 설명 ","date":"2020-06-30","objectID":"/hikaricp/:3:0","tags":["ConnectionPool","Java"],"title":"Hikari Connection Pool 파헤치기","uri":"/hikaricp/"},{"categories":["Java"],"content":"3.1 특징 hikari CP의 특이점이 있다면 아래 코드와 같이 DataSource에 2개의 pool이 존재한다는 것이다. fastPathPool은 전체 pool에서 요청전에 캐시 처럼 사용한다.(volatile을 사용하는 경우 메인메모리에 read/write를 수행하여 일치되는 값을 공유하여 사용할 수 있지만 오버헤드가 있다.) public class HikariDataSource extends HikariConfig implements DataSource, Closeable { private final HikariPool fastPathPool; private volatile HikariPool pool; } 다수의 connection이 동시에 연결/닫기 를 수행했을 때의 병목을 방지 하기 위해서 maxLifeTime의 2.5% 수준의 변화를 주어 timeout값을 설정하여 스케쥴에 등록한다. maxLifeTime 설정된 시간 만큼 connection 을 유지만 하고 갱신하지 않는다.(갱신에 따른 오버헤드 제거) ","date":"2020-06-30","objectID":"/hikaricp/:3:1","tags":["ConnectionPool","Java"],"title":"Hikari Connection Pool 파헤치기","uri":"/hikaricp/"},{"categories":["Java"],"content":"3.2 동작 순서 3.2.1 Connection 가져오기 fastPathPool에서 대여 이력이 있는지를 확인하여 이력이 있는 경우 Connection 요청 fastPathPool에 없으면 Pool에서 Connection 요청 Pool에도 없다면 handoffQueue에서 대기 일정 시간 이내 다른 thread에게 connection이 반납되지 않으면 Exception 발생 Connection이 1000ms(1초) 이내 사용된 경우에는 유효성 검증을 하지 않는다. 3.2.2 Connection 닫기 idle connection으로 변경(state를 STATE_NOT_IN_USE로 변경) handOffQueue에서 대기 쓰레드가 있는지를 확인하여 connection 전달 없다면 pool로 삽입 connection 대여 이력 추가 ","date":"2020-06-30","objectID":"/hikaricp/:3:2","tags":["ConnectionPool","Java"],"title":"Hikari Connection Pool 파헤치기","uri":"/hikaricp/"},{"categories":["Java"],"content":"3.3 주의사항 HikariCP는 test-while-idle Connection 갱신하여 사용하는 것을 권장하지 않는다.(강제 설정하는 것은 가능) maxLifeTime만큼만 connection을 유지하고 새로운 connection을 생성하여 사용한다.(불필요한 Validation Query가 발생하지 않음) **maxLifeTime은 DB의 waitTimeout보다는 작은 값을 설정해야 한다.(2~5 초 : 문서상 30초는 업데이트가 안된거라고 함) ** (참고) HikariCP는 test-while-idle과 같은 커넥션 갱신 기능이 없을까? ","date":"2020-06-30","objectID":"/hikaricp/:3:3","tags":["ConnectionPool","Java"],"title":"Hikari Connection Pool 파헤치기","uri":"/hikaricp/"},{"categories":["Java"],"content":"4 옵션 ","date":"2020-06-30","objectID":"/hikaricp/:4:0","tags":["ConnectionPool","Java"],"title":"Hikari Connection Pool 파헤치기","uri":"/hikaricp/"},{"categories":["Java"],"content":"4.1 Essentials Option Description dataSourceClassName datasource JDBC 드라이버가 제공하는 클래스 이름 jdbcUrl db 접속 url username 사용자명 password 사용자 비밀번호 ","date":"2020-06-30","objectID":"/hikaricp/:4:1","tags":["ConnectionPool","Java"],"title":"Hikari Connection Pool 파헤치기","uri":"/hikaricp/"},{"categories":["Java"],"content":"4.2 Optionals(Frequently used) Option Description autoCommit connection 반납시 commit 여부(default:true) connectionTimeout connection 연결시도시 타임아웃 값 (default:30000(30초)) idleTimeout connection pool에서 유휴 상태의 생명주기 (default:600000(10분)) maxLifetime connection 의 최대 생명주기 (default:1800000(30분)) connectionTestQuery 드라이버가 JDBC4를 지원하는 경우에는 설정하지 않음. legacy 드라이버를 위해 사용 minimumIdle 최소 연결 유휴 connection 수 maximumPoolSize 최대 연결 connection 수 metricRegistry 모니터링용. metric을 기록하는데 사용할 Codahale/Dropwizard의 인스턴스를 지정 healthCheckRegistry 모니터링용. health check 정보를 사용할 Codahale/Dropwizard의 인스턴스를 지정 poolName connection pool의 사용자 이름 정의 ","date":"2020-06-30","objectID":"/hikaricp/:4:2","tags":["ConnectionPool","Java"],"title":"Hikari Connection Pool 파헤치기","uri":"/hikaricp/"},{"categories":["Java"],"content":"4.3 Optionals(Infrequently used) Option Description initializationFailTimeout 초기 연결로 풀에 시드 connection으로 할 수 없을 경우 실패 여부를 제어 (default:1) isolateInternalQueries 서비스용이 아닌 테스트와 같은 내부 풀 쿼리를 분리 여부를 결정. autoCommit이 비활성화된 경우에만 적용 allowPoolSuspension JMX를 통해 pool을 일시 중단하고 재개할 수 있는지 여부를 제어. 특정 장애 조치 자동화 시나리오에 유용 (default:false) readOnly 읽기모드 전용. 데이터베이스 지원여부를 확인하고 사용 가능(default:false) registerMbeans JMX 관리 Bean의 등록 여부 제어 (default:false) catalog 카탈로그 개념을 지원하는 데이터베이스의 기본 카탈로그를 설정. 지정하지 않으면 JDBC 드라이버가 정의한 기본 카탈로그를 사용 connectionInitSql 신규 connection이 pool에 추가되기 전에 실행된 SQL 문 정의 driverClassName 특정 DriverManager를 실행하기 위해 지정하는 특정 Class를 지정 transactionIsolation java.sql.Connection에 지정된 Transaction Isolation 설정 (default:none) validationTimeout connection의 유효한지를 확인할 경우의 타이아웃 값 (default:5000) leakDetectionThreshold connection 이 pool에서 벗어나는 시간을 제어. 누수 여부를 검출시 사용 (default:0) dataSource hikariCP가 reflection을 통해 생성하지 않고 풀의 인스턴스를 바로 랩핑하는 겨우 설정 schema 스키마 개념을 지원하는 데이터베이스의 기본 스키마를 설정 (default:driver default) threadFactory 쓰레드 생성시에 사용할 인스턴스를 지정 scheduledExecutor java.util.concurrent.ScheduledExecutorService 내부적으로 예약 된 다양한 작업에 사용될 인스턴스를 설정 가능 ","date":"2020-06-30","objectID":"/hikaricp/:4:3","tags":["ConnectionPool","Java"],"title":"Hikari Connection Pool 파헤치기","uri":"/hikaricp/"},{"categories":["Java"],"content":"5 참조 HikariCP Dead lock에서 벗어나기 (이론편) JDBC 커넥션 풀들의 리소스 관리 방식 이해하기 Commons DBCP 이해하기 HikariCP 뜯어보기 1편 HikariCP 뜯어보기 2편 HikariCP Failed to Validate Connection Warning 이야기 HikariCP는 test-while-idle과 같은 커넥션 갱신 기능이 없을까? HikariCP Maximum Pool Size 설정 시, 고려해야할 부분 ","date":"2020-06-30","objectID":"/hikaricp/:5:0","tags":["ConnectionPool","Java"],"title":"Hikari Connection Pool 파헤치기","uri":"/hikaricp/"},{"categories":["Java"],"content":"Connection Pool 성능테스트","date":"2020-06-29","objectID":"/connection_pool_benchmark/","tags":["ConnectionPool","Benchmark","Java"],"title":"Connection Pool 성능테스트 : hikari, tomcat-dbcp, bee, vibur","uri":"/connection_pool_benchmark/"},{"categories":["Java"],"content":"Connectino Pool 라이브러리 tomcat-dbcp/vibur/bee/hikari 최신 라이브러리 적용한 성능 검증 분석 회사에서 스프링 프레임워크 업그레이드를 진행하면서 의존성 있는 라이브러리의 목록을 업데이트하는 업무를 진행하게 되었다. 사용하는 라이브러리 중에서 CP(Connection Pool)는 tomcat-dbcp를 사용하고 있었고, 스프링부트 2.0에서 디폴트로 적용된 Hikari CP에 대해 검토하게 되었다. Hikari CP Repository에 성능 비교는 2-3년 전에 진행되었기 때문에 최신 버전과 새로운 CP 라이브러리를 추가하여 성능검증을 진행하였다. ","date":"2020-06-29","objectID":"/connection_pool_benchmark/:0:0","tags":["ConnectionPool","Benchmark","Java"],"title":"Connection Pool 성능테스트 : hikari, tomcat-dbcp, bee, vibur","uri":"/connection_pool_benchmark/"},{"categories":["Java"],"content":"1 성능검증 ","date":"2020-06-29","objectID":"/connection_pool_benchmark/:1:0","tags":["ConnectionPool","Benchmark","Java"],"title":"Connection Pool 성능테스트 : hikari, tomcat-dbcp, bee, vibur","uri":"/connection_pool_benchmark/"},{"categories":["Java"],"content":"1.1 테스트 환경 항목 SPEC OS CentOS 7.7.1908(x86_64) CPU Intel(R) Xeon(R) CPU E5-2660 v2 @2.20GHz,GenuineIntel RAM 8GB JDK openjdk 1.8 ","date":"2020-06-29","objectID":"/connection_pool_benchmark/:1:1","tags":["ConnectionPool","Benchmark","Java"],"title":"Connection Pool 성능테스트 : hikari, tomcat-dbcp, bee, vibur","uri":"/connection_pool_benchmark/"},{"categories":["Java"],"content":"1.2 테스트 대상 라이브러리 라이브러리명 버전 RELEASE 일자 비고 tomcat-dbcp 8.0.53 2018.01.29. dbcp2에 개선 버전이기에 dbcp2를 따로 테스트 항목에 추가하지 않음 hikari 3.4.5 2020.05.08. bee 2.4.2 2020.05.30. vibur 25.0 2019.11.30. ","date":"2020-06-29","objectID":"/connection_pool_benchmark/:1:2","tags":["ConnectionPool","Benchmark","Java"],"title":"Connection Pool 성능테스트 : hikari, tomcat-dbcp, bee, vibur","uri":"/connection_pool_benchmark/"},{"categories":["Java"],"content":"1.3 CP 설정 및 실행 조건 Contended benchmark 테스트로 진행 항목 설정 값 쓰레드 수 32 초기 커넥션 수 20 최대 커넥션 수 20 ","date":"2020-06-29","objectID":"/connection_pool_benchmark/:1:3","tags":["ConnectionPool","Benchmark","Java"],"title":"Connection Pool 성능테스트 : hikari, tomcat-dbcp, bee, vibur","uri":"/connection_pool_benchmark/"},{"categories":["Java"],"content":"1.4 기타 기존 성능 테스트를 위해 구현되었던 HikariCP-benchmark 프로젝트를 기반으로 코드를 재작성하였다. Repository : https://github.com/qnqnckck/ConnectionPoolBenchmark ","date":"2020-06-29","objectID":"/connection_pool_benchmark/:1:4","tags":["ConnectionPool","Benchmark","Java"],"title":"Connection Pool 성능테스트 : hikari, tomcat-dbcp, bee, vibur","uri":"/connection_pool_benchmark/"},{"categories":["Java"],"content":"2 결과 Cycle Connection과 Cycle Statement 2가지 테스트를 진행한다. Cycle Connection : DataSource.getConnection(), Connection.close() Cycle Statement : Connecdtion.prepareStatement(), Statement.execute(), Statement.close() ","date":"2020-06-29","objectID":"/connection_pool_benchmark/:2:0","tags":["ConnectionPool","Benchmark","Java"],"title":"Connection Pool 성능테스트 : hikari, tomcat-dbcp, bee, vibur","uri":"/connection_pool_benchmark/"},{"categories":["Java"],"content":"2.1 Stub Driver 사용 2.1.1 Cycle Connection tomcat-dbcp hikari bee vibur ms당 수행횟수(ops/ms) 1921.732 27429.626 45446.493 2930.534 2.1.2 Cycle Statement tomcat-dbcp hikari bee vibur ms당 수행횟수(ops/ms) 20316.572 28529.254 75904.932 20487.692 ","date":"2020-06-29","objectID":"/connection_pool_benchmark/:2:1","tags":["ConnectionPool","Benchmark","Java"],"title":"Connection Pool 성능테스트 : hikari, tomcat-dbcp, bee, vibur","uri":"/connection_pool_benchmark/"},{"categories":["Java"],"content":"2.2 MySql Driver 사용 2.2.1 Cycle Connection tomcat-dbcp hikari bee vibur ms당 수행횟수(ops/ms) 12.961 31431.702 58562.068 3033.819 2.2.2 Cycle Statement tomcat-dbcp hikari bee vibur ms당 수행횟수(ops/ms) 12.341 12.228 12.455 12.298 ","date":"2020-06-29","objectID":"/connection_pool_benchmark/:2:2","tags":["ConnectionPool","Benchmark","Java"],"title":"Connection Pool 성능테스트 : hikari, tomcat-dbcp, bee, vibur","uri":"/connection_pool_benchmark/"},{"categories":["Java"],"content":"3 분석 Stub 드라이버의 경우 DB 서버 실제 질의를 날리지 않기 때문에 순수 라이브러리의 성능지표이며, 결과만 보면 압도적으로 hikari와 bee 라이브러리가 가장 좋은 성능을 보여주었다. mysql 드라이버의 경우 private 회사망에 분리되어 있는 DB 서버에 접속하여 테스트를 진행하였으며 실제 질의 후 응답까지에 네트워크 시간을 포함한 소요시간이 가장 큰 영향을 끼치기 때문에 결과적으로 다 비슷한 소요시간의 결과를 확인 할 수 있었다. 그렇다면 응답 속도도 동일하면 성능적으로 차이가 없는 것인가? 그렇지 않다. 각각의 라이브러리의 장점들이 있을텐데 hikari의 경우에는 connection을 fastPathPool을 통해 동일 쓰레드 요청에 대 이전에 사용된 connection을 전달해 준다. 이부분에 대해서 성능은 실제 얼마나 응답속도 부분에 대해 기여할지는 추후에 테스트하게 되면 공유 하도록 하겠다. ","date":"2020-06-29","objectID":"/connection_pool_benchmark/:3:0","tags":["ConnectionPool","Benchmark","Java"],"title":"Connection Pool 성능테스트 : hikari, tomcat-dbcp, bee, vibur","uri":"/connection_pool_benchmark/"}]